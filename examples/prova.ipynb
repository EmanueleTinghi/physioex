{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "import math\n",
    "\n",
    "class HardAttentionLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "            hidden_size : int,\n",
    "            attention_size : int, \n",
    "            N : int = 1, # number of elements to select\n",
    "            temperature : float = 1.0,\n",
    "            encoding : nn.Module = None\n",
    "        ):\n",
    "        super(HardAttentionLayer, self).__init__()\n",
    "        \n",
    "        self.temperature = temperature\n",
    "        \n",
    "        self.pe = PositionalEncoding(hidden_size, 100)\n",
    "        \n",
    "        self.N = N\n",
    "\n",
    "        self.Q = nn.Linear(hidden_size, attention_size * N, bias = False)\n",
    "        self.K = nn.Linear(hidden_size, attention_size * N, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, sequence_length, hidden_size = x.size()\n",
    "\n",
    "        # encode the sequence with positional encoding\n",
    "        pos_emb = self.pe(x)\n",
    "\n",
    "        # calculate the query and key\n",
    "        Q = self.Q(pos_emb)\n",
    "        K = self.K(pos_emb)\n",
    "        \n",
    "        Q = Q.reshape( batch_size, sequence_length, self.N, -1 ).transpose(1, 2)\n",
    "        K = K.reshape( batch_size, sequence_length, self.N, -1 ).transpose(1, 2)\n",
    "        \n",
    "        attention = torch.einsum( \"bnsh,bnth -> bnst\", Q, K ) / math.sqrt( hidden_size )\n",
    "        attention = torch.sum(attention, dim=-1) / sequence_length\n",
    "\n",
    "        # attention shape : (batch_size * N, sequence_length)\n",
    "        logits = attention.reshape( batch_size * self.N, sequence_length )                \n",
    "        # apply the Gumbel-Softmax trick to select the N most important elements\n",
    "        alphas = torch.nn.functional.gumbel_softmax(logits, tau=self.temperature, hard=True)\n",
    "        alphas = alphas.reshape( batch_size, self.N, sequence_length )\n",
    "        \n",
    "        # select N elements from the sequence x using alphas\n",
    "        x = torch.einsum( \"bns, bsh -> bnh\", alphas, x )\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, hidden_size, max_len=5000):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
    "        pe = torch.zeros(max_len, hidden_size)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, hidden_size, 2).float() * (-math.log(10000.0) / hidden_size))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer(\"pe\", pe, persistent=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shape x : (batch_size, seq_len, hidden_size)\n",
    "        x = x + self.pe[:, : x.size(1)]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochEncoder( nn.Module ):\n",
    "    def __init__( self, \n",
    "        hidden_size : int,\n",
    "        attention_size : int,\n",
    "        N : int = 1, # number of elements to select\n",
    "        temperature : float = 1.0\n",
    "        ):\n",
    "        super(EpochEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # we need to extract frequency-related features from the signal\n",
    "        self.conv1 = nn.Sequential( OrderedDict([\n",
    "            (\"conv1\", nn.Conv1d(N, 32, 5)),\n",
    "            (\"relu1\", nn.ReLU()),\n",
    "            (\"maxpool1\", nn.MaxPool1d(5)),\n",
    "            (\"conv2\", nn.Conv1d(32, 64, 5)),\n",
    "            (\"relu2\", nn.ReLU()),\n",
    "            (\"maxpool2\", nn.MaxPool1d(5)),\n",
    "            (\"conv3\", nn.Conv1d(64, 128, 5)),\n",
    "            (\"relu3\", nn.ReLU()),\n",
    "            (\"maxpool3\", nn.MaxPool1d(5)),\n",
    "            (\"conv4\", nn.Conv1d(128, 256, 3)),\n",
    "            (\"relu4\", nn.ReLU()),\n",
    "            (\"flatten\", nn.Flatten())\n",
    "        ]))\n",
    "        \n",
    "        self.out_size = self.conv1(torch.randn(1, N,  hidden_size)).shape[1]\n",
    "        \n",
    "        self.sampler = HardAttentionLayer(hidden_size, attention_size, N, temperature)\n",
    "        \n",
    "    def forward( self, x ):\n",
    "        # x shape : (batch_size, seq_len, n_chan, n_samp)\n",
    "        batch_size, seq_len, n_chan, n_samp = x.size()\n",
    "\n",
    "        assert n_samp % self.hidden_size == 0, \"Hidden size must be a divisor of the number of samples\"\n",
    "\n",
    "        x = x.reshape( batch_size * seq_len, n_chan*(n_samp//self.hidden_size), -1 )\n",
    "        print( x.shape )\n",
    "        x = self.sampler( x ) # shape : (batch_size * seq_len, N, hidden_size)\n",
    "        \n",
    "        print( x.shape )\n",
    "        x = self.conv1( x ) # shape : (batch_size * seq_len, out_size)\n",
    "        print( x.shape )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EpochEncoder(\n",
      "  (conv1): Sequential(\n",
      "    (conv1): Conv1d(1, 32, kernel_size=(5,), stride=(1,))\n",
      "    (relu1): ReLU()\n",
      "    (maxpool1): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv1d(32, 64, kernel_size=(5,), stride=(1,))\n",
      "    (relu2): ReLU()\n",
      "    (maxpool2): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv3): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "    (relu3): ReLU()\n",
      "    (maxpool3): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv4): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
      "    (relu4): ReLU()\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (sampler): HardAttentionLayer(\n",
      "    (pe): PositionalEncoding()\n",
      "    (Q): Linear(in_features=600, out_features=128, bias=False)\n",
      "    (K): Linear(in_features=600, out_features=128, bias=False)\n",
      "  )\n",
      ")\n",
      "torch.Size([672, 15, 600])\n",
      "torch.Size([672, 1, 600])\n",
      "torch.Size([672, 256])\n"
     ]
    }
   ],
   "source": [
    "layer = EpochEncoder( \n",
    "    hidden_size = 3000 // 5,\n",
    "    attention_size = 128,\n",
    "    )\n",
    "\n",
    "print( layer )\n",
    "\n",
    "x = torch.randn( 32, 21, 3, 3000 )\n",
    "\n",
    "y = layer(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physioex-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
