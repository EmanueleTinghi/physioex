{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources as pkg\n",
    "\n",
    "path = pkg.resource_filename(__name__, \"../\")\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "#from physioex.data import SleepPhysionet, TimeDistributedModule\n",
    "#from physioex.data import datamodule\n",
    "#from physioex.train.networks import TinySleepNet, ContrTinySleepNet\n",
    "#from physioex.train.networks import seqsleepnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_projections(model, datamodule, contr=False):\n",
    "    train_projections = []\n",
    "    y_train_true = []\n",
    "    y_train_pred = []\n",
    "    first = True\n",
    "    for batch in datamodule.train_dataloader():\n",
    "        inputs, y_true = batch          \n",
    "\n",
    "        y_train_true.append(y_true)\n",
    "        if contr:\n",
    "            projections, y_pred = model(inputs.to(model.device))\n",
    "        else:\n",
    "            projections, y_pred = model.encode(inputs.to(model.device))\n",
    "\n",
    "        y_train_pred.append(y_pred.cpu().detach().numpy())\n",
    "        train_projections.append(projections.cpu().detach().numpy())\n",
    "\n",
    "        del projections, y_pred\n",
    "\n",
    "    y_train_true = np.concatenate(y_train_true).reshape(-1)\n",
    "    train_projections = np.concatenate(train_projections).reshape(\n",
    "        y_train_true.shape[0], -1\n",
    "    )\n",
    "    y_train_pred = np.concatenate(y_train_pred).reshape(-1, 5)\n",
    "\n",
    "    return train_projections, y_train_true, y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from physioex.models import load_pretrained_model\n",
    "path_ssn = \"/home/tinghi/physioex/models/ssn_scl/fold=-1-epoch=17-step=28348-val_acc=0.83.ckpt\"\n",
    "path_ssn_sum = \"/home/tinghi/physioex/models/ssn_epseq_sum_scl/fold=-1-epoch=18-step=29323-val_acc=0.82.ckpt\"\n",
    "path_ssn_conc = \"/home/tinghi/physioex/models/ssn_epseq_conc_scl/fold=-1-epoch=16-step=25482-val_acc=0.82.ckpt\"\n",
    "path_ssn_epoch = \"/home/tinghi/physioex/models/ssn_ep_scl/fold=-1-epoch=17-step=28348-val_acc=0.81.ckpt\"\n",
    "\n",
    "seqsleepnet_model = load_pretrained_model(\"seqsleepnet\", in_channels=1, sequence_length=10, loss=\"scl\", ckpt_path=path_ssn).eval()\n",
    "seqsleepnet_sum_model = load_pretrained_model(\"seqsleepnet\", in_channels=1, sequence_length=10, loss=\"scl\", ckpt_path=path_ssn_sum).eval()\n",
    "seqsleepnet_conc_model = load_pretrained_model(\"seqsleepnet\", in_channels=1, sequence_length=10, loss=\"scl\", ckpt_path=path_ssn_conc).eval()\n",
    "seqsleepnet_epoch_model = load_pretrained_model(\"seqsleepnet\", in_channels=1, sequence_length=10, loss=\"scl\", ckpt_path=path_ssn_epoch).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from physioex.data.datamodule import PhysioExDataModule\n",
    "\n",
    "datamodule = PhysioExDataModule(\n",
    "    datasets=[\"mass\"],\n",
    "    versions=None,\n",
    "    batch_size=15,\n",
    "    selected_channels=[\"EEG\"],\n",
    "    sequence_length=10,\n",
    "    data_folder=\"/mnt/guido-data/\",\n",
    "    preprocessing = \"xsleepnet\",\n",
    "    target_transform= None\n",
    ")\n",
    "\n",
    "#print(datamodule.train_idx[206579])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(datamodule.dataset))\n",
    "print(\"---\")\n",
    "print(len(datamodule.dataset[0]))\n",
    "print(type(datamodule.dataset[0][0]), \" \", type(datamodule.dataset[0][1]))\n",
    "print(\"---\")\n",
    "print(len(datamodule.dataset[0][0]))\n",
    "print(datamodule.dataset[0][1])\n",
    "print(\"---\")\n",
    "print(datamodule.dataset[0][0][1].shape)\n",
    "print(\"---\")\n",
    "\n",
    "tdl = datamodule.train_dataloader()\n",
    "print(len(datamodule.train_idx))\n",
    "print(datamodule.batch_size)\n",
    "print(len(tdl))\n",
    "print(len(tdl.dataset))\n",
    "print(len(tdl.dataset[0]))\n",
    "print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Assuming the tensor is obtained from the dataset\n",
    "tensor1 = datamodule.dataset.__getitem__(0)[0][0]\n",
    "tensor2 = datamodule.dataset.__getitem__(1300)[0][0]\n",
    "\n",
    "first_dim = torch.arange(29)\n",
    "second_dim = torch.arange(129)\n",
    "third_dim1 = tensor1[0, first_dim[:, None], second_dim]\n",
    "third_dim2 = tensor2[0, first_dim[:, None], second_dim]\n",
    "# Create a meshgrid for the x and y coordinates\n",
    "X, Y = torch.meshgrid(first_dim, second_dim, indexing='ij')\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Plot the first spectrogram\n",
    "c1 = ax1.pcolormesh(X, Y, third_dim1, shading='auto')\n",
    "fig.colorbar(c1, ax=ax1, label='Intensity')\n",
    "ax1.set_xlabel('First Dimension (x-coordinates)')\n",
    "ax1.set_ylabel('Second Dimension (y-coordinates)')\n",
    "ax1.set_title('Spectrogram 1')\n",
    "\n",
    "# Plot the second spectrogram (assuming you have another tensor for the second plot)\n",
    "# For demonstration, we'll use the same tensor\n",
    "c2 = ax2.pcolormesh(X, Y, third_dim2, shading='auto')\n",
    "fig.colorbar(c2, ax=ax2, label='Intensity')\n",
    "ax2.set_xlabel('First Dimension (x-coordinates)')\n",
    "ax2.set_ylabel('Second Dimension (y-coordinates)')\n",
    "ax2.set_title('Spectrogram 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from physioex.models import load_pretrained_model\n",
    "#path_ep_scl_MSM_EW = \"/home/tinghi/physioex/models/ssn_ep_scl/fold=-1-epoch=17-step=28348-val_acc=0.81.ckpt\"\n",
    "path_ep_scl_BEHM_DW = \"/home/tinghi/physioex/models/new_weights_in_cel/ssn_ep_scl/fold=-1-epoch=19-step=30908-val_acc=0.75.ckpt\"\n",
    "#seqsleepnet_model_MSM_EW = load_pretrained_model(\"seqsleepnet\", in_channels=1, sequence_length=10, loss=\"scl\", ckpt_path=path_ep_scl_MSM_EW).eval()\n",
    "seqsleepnet_model_BEHM_DW = load_pretrained_model(\"seqsleepnet\", in_channels=1, sequence_length=10, loss=\"scl\", ckpt_path=path_ep_scl_BEHM_DW).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from physioex.models import load_pretrained_model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_ep_scl_BEHM_DW = \"/home/tinghi/physioex/models/new_weights_in_cel/ssn_ep_scl/fold=-1-epoch=19-step=30908-val_acc=0.75.ckpt\"\n",
    "# First, load the model without strict argument\n",
    "seqsleepnet_model_BEHM_DW = load_pretrained_model(\"seqsleepnet\", in_channels=1, sequence_length=21, loss_params={\"class_weights\": torch.tensor([7.6, 15, 2.1, 9, 6])} ,loss=\"scl\", ckpt_path=path_ep_scl_BEHM_DW)\n",
    "# Then, load the checkpoint with strict=False\n",
    "checkpoint = torch.load(path_ep_scl_BEHM_DW, map_location='cuda')\n",
    "seqsleepnet_model_BEHM_DW.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "seqsleepnet_model_BEHM_DW.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ep_scl_MSM_EW = \"/home/tinghi/physioex/models/ssn_ep_scl/fold=-1-epoch=17-step=28348-val_acc=0.81.ckpt\"\n",
    "# First, load the model without strict argument\n",
    "seqsleepnet_model_MSM_EW = load_pretrained_model(\"seqsleepnet\", in_channels=1, sequence_length=21, loss=\"scl\", ckpt_path=path_ep_scl_MSM_EW)\n",
    "# Then, load the checkpoint with strict=False\n",
    "checkpoint = torch.load(path_ep_scl_MSM_EW, map_location='cuda')\n",
    "seqsleepnet_model_MSM_EW.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "seqsleepnet_model_MSM_EW.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ep_scl_BEHM_EW = \"/home/tinghi/physioex/models/behm_oneweight/ssn_ep_scl/fold=-1-epoch=10-step=17070-val_acc=0.81.ckpt\"\n",
    "# First, load the model without strict argument\n",
    "seqsleepnet_model_BEHM_EW = load_pretrained_model(\"seqsleepnet\", in_channels=1, sequence_length=21, loss=\"scl\", ckpt_path=path_ep_scl_BEHM_EW)\n",
    "# Then, load the checkpoint with strict=False\n",
    "checkpoint = torch.load(path_ep_scl_BEHM_EW, map_location='cuda')\n",
    "seqsleepnet_model_BEHM_EW.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "seqsleepnet_model_BEHM_EW.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from physioex.data.datamodule import PhysioExDataModule\n",
    "\n",
    "datamodule = PhysioExDataModule(\n",
    "    datasets=[\"mass\"],\n",
    "    versions=None,\n",
    "    batch_size=15,\n",
    "    selected_channels=[\"EEG\"],\n",
    "    sequence_length=10,\n",
    "    data_folder=\"/mnt/guido-data/\",\n",
    "    preprocessing = \"xsleepnet\",\n",
    "    target_transform= None,\n",
    ")\n",
    "print(len(datamodule.dataset))\n",
    "print(len(datamodule.dataset[0]))\n",
    "print(len(datamodule.dataset[0][0]))\n",
    "print(datamodule.dataset[0][0][1].shape)\n",
    "print(datamodule.dataset[2359][1])\n",
    "\n",
    "'''class_count = [0, 0, 0, 0, 0]\n",
    "for i in range(0, len(datamodule.dataset)):\n",
    "    for j in range(0, len(datamodule.dataset[i][1])):\n",
    "        class_count[datamodule.dataset[i][1][j]] += 1\n",
    "\n",
    "    if(i%1000 == 0):\n",
    "        print(i)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_count)\n",
    "print(np.sum(class_count))\n",
    "class_balancer = np.round(np.sum(class_count)/class_count,1)\n",
    "print(class_balancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Assuming the tensor is obtained from the dataset\n",
    "tensor1 = datamodule.dataset.__getitem__(0)[0][0]\n",
    "tensor2 = datamodule.dataset.__getitem__(1300)[0][0]\n",
    "\n",
    "first_dim = torch.arange(29)\n",
    "second_dim = torch.arange(129)\n",
    "third_dim1 = tensor1[0, first_dim[:, None], second_dim]\n",
    "third_dim2 = tensor2[0, first_dim[:, None], second_dim]\n",
    "# Create a meshgrid for the x and y coordinates\n",
    "X, Y = torch.meshgrid(first_dim, second_dim, indexing='ij')\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Plot the first spectrogram\n",
    "c1 = ax1.pcolormesh(X, Y, third_dim1, shading='auto')\n",
    "fig.colorbar(c1, ax=ax1, label='Intensity')\n",
    "ax1.set_xlabel('First Dimension (x-coordinates)')\n",
    "ax1.set_ylabel('Second Dimension (y-coordinates)')\n",
    "ax1.set_title('Spectrogram 1')\n",
    "\n",
    "# Plot the second spectrogram (assuming you have another tensor for the second plot)\n",
    "# For demonstration, we'll use the same tensor\n",
    "c2 = ax2.pcolormesh(X, Y, third_dim2, shading='auto')\n",
    "fig.colorbar(c2, ax=ax2, label='Intensity')\n",
    "ax2.set_xlabel('First Dimension (x-coordinates)')\n",
    "ax2.set_ylabel('Second Dimension (y-coordinates)')\n",
    "ax2.set_title('Spectrogram 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train dataloader\n",
    "train_dataloader = datamodule.train_dataloader()\n",
    "\n",
    "# Create an iterator from the dataloader\n",
    "train_dataloader_iter = iter(train_dataloader)\n",
    "\n",
    "# Get the first element\n",
    "first_element = next(train_dataloader_iter)\n",
    "\n",
    "# Print the first element\n",
    "print(first_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train dataloader\n",
    "train_dataloader = datamodule.train_dataloader()\n",
    "\n",
    "# Create an iterator from the dataloader\n",
    "train_dataloader_iter = iter(train_dataloader)\n",
    "\n",
    "# Get the first element\n",
    "first_element = next(train_dataloader_iter)\n",
    "\n",
    "# Print the first element\n",
    "print(first_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA components plot\n",
    "\n",
    "### Extracting the latent space projections from the similarity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqsleepnet_model\n",
    "seqsleepnet_sum_model\n",
    "seqsleepnet_conc_model\n",
    "seqsleepnet_epoch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_projections, y_train_true, y_train_pred = compute_projections(\n",
    "    seqsleepnet_model_BEHM_EW, datamodule, contr=False\n",
    ")\n",
    "preds_snn = np.argmax(y_train_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "print(y_train_true.shape)\n",
    "print(preds_snn.shape)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_train_true, preds_snn)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix for BatchEasyHardMiner with Different Weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the number of components to see the variance in other components\n",
    "pca = PCA(n_components=2)  # Adjust the number of components as needed\n",
    "true_indx = [True for i in range(len(y_train_true))]\n",
    "# Fourth PCA transformation\n",
    "principal_components = pca.fit_transform(train_projections[true_indx, :])\n",
    "true_positive = y_train_true[true_indx]\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "df_ssn = pd.DataFrame(\n",
    "    {\n",
    "        \"First Principal Component\": principal_components[:, 0],\n",
    "        \"Second Principal Component\": principal_components[:, 1],\n",
    "        \"Group\": true_positive,\n",
    "    }\n",
    ")\n",
    "print(\"Explained variance ratio:\", explained_variance)\n",
    "print(\"Explained variance:\", explained_variance.sum())\n",
    "\n",
    "classes = {0:\"Wake\", 1:\"N1\", 2:\"N2\", 3:\"N3\", 4:\"REM\"}\n",
    "df_ssn[\"Group\"] = df_ssn[\"Group\"].map(classes)\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(16, 11))\n",
    "classes=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "\n",
    "# Utilizza seaborn.scatterplot\n",
    "sns.scatterplot(\n",
    "    data=df_ssn[(df_ssn[\"First Principal Component\"] >= -0.4)&(df_ssn[\"First Principal Component\"] <= 0.4)],\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"Group\",\n",
    "    hue_order=classes,\n",
    "    palette=\"Set1\",\n",
    ").set(title=\"BEHM_EW\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_projections_ssn, y_train_true_ssn, y_train_pred_ssn = compute_projections(\n",
    "    seqsleepnet_model, datamodule, contr=False\n",
    ")\n",
    "preds_snn = np.argmax(y_train_pred_ssn, axis=1)\n",
    "print(\"ssn end\")\n",
    "\n",
    "train_projections_ssn_sum, y_train_true_ssn_sum, y_train_pred_ssn_sum = compute_projections(\n",
    "    seqsleepnet_sum_model, datamodule, contr=False\n",
    ")\n",
    "preds_snn_sum = np.argmax(y_train_pred_ssn_sum, axis=1)\n",
    "print(\"ssn sum end\")\n",
    "\n",
    "train_projections_ssn_conc, y_train_true_ssn_conc, y_train_pred_ssn_conc = compute_projections(\n",
    "    seqsleepnet_conc_model, datamodule, contr=False\n",
    ")\n",
    "preds_snn_conc = np.argmax(y_train_pred_ssn_conc, axis=1)\n",
    "print(\"ssn conc end\")\n",
    "\n",
    "train_projections_ssn_epoch, y_train_true_ssn_epoch, y_train_pred_ssn_epoch = compute_projections(\n",
    "    seqsleepnet_epoch_model, datamodule, contr=False\n",
    ")\n",
    "preds_snn_epoch = np.argmax(y_train_pred_ssn_epoch, axis=1)\n",
    "print(\"ssn epoch end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_indx_ssn = [True for i in range(len(y_train_true_ssn))]\n",
    "true_indx_ssn_sum = [True for i in range(len(y_train_true_ssn_sum))]\n",
    "true_indx_ssn_conc = [True for i in range(len(y_train_true_ssn_conc))]\n",
    "true_indx_ssn_epoch = [True for i in range(len(y_train_true_ssn_epoch))]\n",
    "#true_indx = [True for i in range(len(contr_y_train_true))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import math\n",
    "\n",
    "'''seqsleepnet_model\n",
    "seqsleepnet_sum_model\n",
    "seqsleepnet_conc_model\n",
    "seqsleepnet_epoch_model'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_projections = train_projections\n",
    "y_train_true = y_train_true\n",
    "figure_title = \"SSN-Epoch-BEHM_EW\" + \" SimilarityCombinedLoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = datamodule.dataset.scaling[0][0]\n",
    "std = datamodule.dataset.scaling[0][1]\n",
    "print(mean.shape)\n",
    "print(std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_projections_df = pd.DataFrame(train_projections)\n",
    "y_train_true_df = pd.DataFrame(y_train_true, columns=['y_train_true'])\n",
    "\n",
    "result_df = pd.concat([train_projections_df, y_train_true_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the dataset\n",
    "sampled_df = result_df.sample(n=20000, random_state=0)  # Adjust the sample size as needed\n",
    "medoids_idxs = {}\n",
    "\n",
    "# Iterate over each unique class in the 'y_train_true' column\n",
    "for class_label in sampled_df['y_train_true'].unique():\n",
    "    # Filter the dataframe to include only rows of the current class\n",
    "    class_df = sampled_df[sampled_df['y_train_true'] == class_label]\n",
    "    \n",
    "    # Apply k-medoids clustering with k=1\n",
    "    kmedoids = KMedoids(n_clusters=1, random_state=0)\n",
    "    kmedoids.fit(class_df.iloc[:, :-1])  # Exclude the 'y_train_true' column\n",
    "    \n",
    "    # Retrieve the index of the cluster center in the original sampled_df\n",
    "    medoid_index = class_df.index[kmedoids.medoid_indices_][0]\n",
    "    print(f\"Index of the cluster center in the original sampled_df for class {class_label}: {medoid_index}\")\n",
    "    medoids_idxs[class_label] = medoid_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "medoid_0 = datamodule.dataset[math.floor(medoids_idxs[0]/10)][0][medoids_idxs[0]%10]\n",
    "medoid_1 = datamodule.dataset[math.floor(medoids_idxs[1]/10)][0][medoids_idxs[1]%10]\n",
    "medoid_2 = datamodule.dataset[math.floor(medoids_idxs[2]/10)][0][medoids_idxs[2]%10]\n",
    "medoid_3 = datamodule.dataset[math.floor(medoids_idxs[3]/10)][0][medoids_idxs[3]%10]\n",
    "medoid_4 = datamodule.dataset[math.floor(medoids_idxs[4]/10)][0][medoids_idxs[4]%10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for demonstration\n",
    "first_dim = torch.arange(29)\n",
    "second_dim = torch.arange(129)\n",
    "\n",
    "third_dim0 = (10 ** ((medoid_0[0, first_dim[:, None], second_dim]*std + mean)/20) - np.finfo(float).eps).squeeze()\n",
    "third_dim1 = (10 ** ((medoid_1[0, first_dim[:, None], second_dim]*std + mean)/20) - np.finfo(float).eps).squeeze()\n",
    "third_dim2 = (10 ** ((medoid_2[0, first_dim[:, None], second_dim]*std + mean)/20) - np.finfo(float).eps).squeeze()\n",
    "third_dim3 = (10 ** ((medoid_3[0, first_dim[:, None], second_dim]*std + mean)/20) - np.finfo(float).eps).squeeze()\n",
    "third_dim4 = (10 ** ((medoid_4[0, first_dim[:, None], second_dim]*std + mean)/20) - np.finfo(float).eps).squeeze()\n",
    "\n",
    "third_dim0 = third_dim0[:, :50]\n",
    "third_dim1 = third_dim1[:, :50]\n",
    "third_dim2 = third_dim2[:, :50]\n",
    "third_dim3 = third_dim3[:, :50]\n",
    "third_dim4 = third_dim4[:, :50]\n",
    "second_dim = second_dim[:50]\n",
    "\n",
    "# Create a meshgrid for the x and y coordinates\n",
    "X, Y = torch.meshgrid(first_dim, second_dim, indexing='ij')\n",
    "\n",
    "#vmin = min(third_dim0.min(), third_dim1.min(), third_dim2.min(), third_dim3.min(), third_dim4.min())\n",
    "#vmax = max( third_dim0.max(), third_dim1.max(), third_dim2.max(), third_dim3.max(), third_dim4.max())\n",
    "\n",
    "# Create a figure with a custom grid layout\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = fig.add_gridspec(3, 2, height_ratios=[1, 1, 1])\n",
    "# Add a title to the entire figure\n",
    "fig.suptitle(figure_title, fontsize=25)\n",
    "\n",
    "# First row, first column\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "#c1 = ax1.pcolormesh(X, Y, third_dim0, shading='auto', vmin=vmin, vmax=vmax)\n",
    "c1 = ax1.pcolormesh(X, Y, third_dim0, shading='auto')\n",
    "fig.colorbar(c1, ax=ax1, label='Intensity')\n",
    "ax1.set_xlabel(\"Spectral Column\")\n",
    "ax1.set_ylabel(\"Frequency Bin\")\n",
    "ax1.set_title('Wake Centroid Spectrogram')\n",
    "\n",
    "# First row, second column\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "#c2 = ax2.pcolormesh(X, Y, third_dim1, shading='auto', vmin=vmin, vmax=vmax)\n",
    "c2 = ax2.pcolormesh(X, Y, third_dim1, shading='auto')\n",
    "fig.colorbar(c2, ax=ax2, label='Intensity')\n",
    "ax2.set_xlabel(\"Spectral Column\")\n",
    "ax2.set_ylabel(\"Frequency Bin\")\n",
    "ax2.set_title('N1 Centroid Spectrogram')\n",
    "\n",
    "# Second row, first column\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "#c3 = ax3.pcolormesh(X, Y, third_dim2, shading='auto', vmin=vmin, vmax=vmax)\n",
    "c3 = ax3.pcolormesh(X, Y, third_dim2, shading='auto')\n",
    "fig.colorbar(c3, ax=ax3, label='Intensity')\n",
    "ax3.set_xlabel(\"Spectral Column\")\n",
    "ax3.set_ylabel(\"Frequency Bin\")\n",
    "ax3.set_title('N2 Centroid Spectrogram')\n",
    "\n",
    "# Second row, second column\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "#c4 = ax4.pcolormesh(X, Y, third_dim3, shading='auto', vmin=vmin, vmax=vmax)\n",
    "c4 = ax4.pcolormesh(X, Y, third_dim3, shading='auto')\n",
    "fig.colorbar(c4, ax=ax4, label='Intensity')\n",
    "ax4.set_xlabel(\"Spectral Column\")\n",
    "ax4.set_ylabel(\"Frequency Bin\")\n",
    "ax4.set_title('N3 Centroid Spectrogram')\n",
    "\n",
    "# Third row, centered column (spanning both columns)\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "#c5 = ax5.pcolormesh(X, Y, third_dim4, shading='auto', vmin=vmin, vmax=vmax)\n",
    "c5 = ax5.pcolormesh(X, Y, third_dim4, shading='auto')\n",
    "fig.colorbar(c5, ax=ax5, label='Intensity')\n",
    "ax5.set_xlabel(\"Spectral Column\")\n",
    "ax5.set_ylabel(\"Frequency Bin\")\n",
    "ax5.set_title('REM Centroid Spectrogram')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the first 2 PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the number of components to see the variance in other components\n",
    "pca = PCA(n_components=2)  # Adjust the number of components as needed\n",
    "\n",
    "# First PCA transformation\n",
    "principal_components_ssn = pca.fit_transform(train_projections_ssn[true_indx_ssn, :])\n",
    "true_positive_ssn = y_train_true_ssn[true_indx_ssn]\n",
    "explained_variance_ssn = pca.explained_variance_ratio_\n",
    "\n",
    "df_ssn = pd.DataFrame(\n",
    "    {\n",
    "        \"First Principal Component\": principal_components_ssn[:, 0],\n",
    "        \"Second Principal Component\": principal_components_ssn[:, 1],\n",
    "        #\"Third Principal Component\": principal_components_ssn[:, 2],\n",
    "        \"Group\": true_positive_ssn,\n",
    "    }\n",
    ")\n",
    "print(\"Explained variance ratio for ssn:\", explained_variance_ssn)\n",
    "print(\"Explained variance:\", explained_variance_ssn.sum())\n",
    "\n",
    "# Second PCA transformation\n",
    "principal_components_ssn_sum = pca.fit_transform(train_projections_ssn_sum[true_indx_ssn_sum, :])\n",
    "true_positive_ssn_sum = y_train_true_ssn_sum[true_indx_ssn_sum]\n",
    "explained_variance_ssn_sum = pca.explained_variance_ratio_\n",
    "\n",
    "df_ssn_sum = pd.DataFrame(\n",
    "    {\n",
    "        \"First Principal Component\": principal_components_ssn_sum[:, 0],\n",
    "        \"Second Principal Component\": principal_components_ssn_sum[:, 1],\n",
    "        #\"Third Principal Component\": principal_components_ssn_sum[:, 2],\n",
    "        \"Group\": true_positive_ssn_sum,\n",
    "    }\n",
    ")\n",
    "print(\"Explained variance ratio for ssn_sum:\", explained_variance_ssn_sum)\n",
    "print(\"Explained variance:\", explained_variance_ssn_sum.sum())\n",
    "\n",
    "# Third PCA transformation\n",
    "principal_components_ssn_conc = pca.fit_transform(train_projections_ssn_conc[true_indx_ssn_conc, :])\n",
    "true_positive_ssn_conc = y_train_true_ssn_conc[true_indx_ssn_conc]\n",
    "explained_variance_ssn_conc = pca.explained_variance_ratio_\n",
    "\n",
    "df_ssn_conc = pd.DataFrame(\n",
    "    {\n",
    "        \"First Principal Component\": principal_components_ssn_conc[:, 0],\n",
    "        \"Second Principal Component\": principal_components_ssn_conc[:, 1],\n",
    "        #\"Third Principal Component\": principal_components_ssn_conc[:, 2],\n",
    "        \"Group\": true_positive_ssn_conc,\n",
    "    }\n",
    ")\n",
    "print(\"Explained variance ratio for ssn_conc:\", explained_variance_ssn_conc)\n",
    "print(\"Explained variance:\", explained_variance_ssn_conc.sum())\n",
    "\n",
    "# Fourth PCA transformation\n",
    "principal_components_ssn_epoch = pca.fit_transform(train_projections_ssn_epoch[true_indx_ssn_epoch, :])\n",
    "true_positive_ssn_epoch = y_train_true_ssn_epoch[true_indx_ssn_epoch]\n",
    "explained_variance_ssn_epoch = pca.explained_variance_ratio_\n",
    "\n",
    "df_ssn_epoch = pd.DataFrame(\n",
    "    {\n",
    "        \"First Principal Component\": principal_components_ssn_epoch[:, 0],\n",
    "        \"Second Principal Component\": principal_components_ssn_epoch[:, 1],\n",
    "        #\"Third Principal Component\": principal_components_ssn_epoch[:, 2],\n",
    "        \"Group\": true_positive_ssn_epoch,\n",
    "    }\n",
    ")\n",
    "print(\"Explained variance ratio for ssn_epoch:\", explained_variance_ssn_epoch)\n",
    "print(\"Explained variance:\", explained_variance_ssn_epoch.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0:\"Wake\", 1:\"N1\", 2:\"N2\", 3:\"N3\", 4:\"REM\"}\n",
    "df_ssn[\"Group\"] = df_ssn[\"Group\"].map(classes)\n",
    "df_ssn_epoch[\"Group\"] = df_ssn_epoch[\"Group\"].map(classes)\n",
    "df_ssn_conc[\"Group\"] = df_ssn_conc[\"Group\"].map(classes)\n",
    "df_ssn_sum[\"Group\"] = df_ssn_sum[\"Group\"].map(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Base\", df_ssn[\"Group\"].unique())\n",
    "print(\"Epoch\", df_ssn_epoch[\"Group\"].unique())\n",
    "print(\"Conc\", df_ssn_conc[\"Group\"].unique())\n",
    "print(\"Sum\", df_ssn_sum[\"Group\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 11))\n",
    "classes=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_ssn_epoch[(df_ssn_epoch[\"First Principal Component\"] >= -0.4)&(df_ssn_epoch[\"First Principal Component\"] <= 0.4)],\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"Group\",\n",
    "    hue_order=classes,\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[0,1],\n",
    ").set(title=\"SeqSleepNet SCL Epoch encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the classes variable\n",
    "classes = [\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "# First subplot\n",
    "ax1 = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "ax1.scatter(\n",
    "    df_ssn[\"First Principal Component\"],\n",
    "    df_ssn[\"Second Principal Component\"],\n",
    "    df_ssn[\"Third Principal Component\"],\n",
    "    c=df_ssn[\"Group\"].apply(lambda x: classes.index(x)),\n",
    "    cmap=\"Set1\"\n",
    ")\n",
    "ax1.set_title(\"SeqSleepNet SCL\")\n",
    "ax1.set_xlabel(\"First Principal Component\")\n",
    "ax1.set_ylabel(\"Second Principal Component\")\n",
    "ax1.set_zlabel(\"Third Principal Component\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the classes variable\n",
    "classes = [\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "\n",
    "fig = plt.figure(figsize=(16, 11))\n",
    "\n",
    "# First subplot\n",
    "ax1 = fig.add_subplot(2, 2, 1, projection='3d')\n",
    "ax1.scatter(\n",
    "    df_ssn[\"First Principal Component\"],\n",
    "    df_ssn[\"Second Principal Component\"],\n",
    "    df_ssn[\"Third Principal Component\"],\n",
    "    c=df_ssn[\"Group\"].apply(lambda x: classes.index(x)),\n",
    "    cmap=\"Set1\"\n",
    ")\n",
    "ax1.set_title(\"SeqSleepNet SCL\")\n",
    "ax1.set_xlabel(\"First Principal Component\")\n",
    "ax1.set_ylabel(\"Second Principal Component\")\n",
    "ax1.set_zlabel(\"Third Principal Component\")\n",
    "\n",
    "# Second subplot\n",
    "ax2 = fig.add_subplot(2, 2, 2, projection='3d')\n",
    "filtered_df = df_ssn_epoch[(df_ssn_epoch[\"First Principal Component\"] >= -0.4) & (df_ssn_epoch[\"First Principal Component\"] <= 0.4)]\n",
    "ax2.scatter(\n",
    "    filtered_df[\"First Principal Component\"],\n",
    "    filtered_df[\"Second Principal Component\"],\n",
    "    filtered_df[\"Third Principal Component\"],\n",
    "    c=filtered_df[\"Group\"].apply(lambda x: classes.index(x)),\n",
    "    cmap=\"Set1\"\n",
    ")\n",
    "ax2.set_title(\"SeqSleepNet SCL Epoch encoding\")\n",
    "ax2.set_xlabel(\"First Principal Component\")\n",
    "ax2.set_ylabel(\"Second Principal Component\")\n",
    "ax2.set_zlabel(\"Third Principal Component\")\n",
    "\n",
    "# Third subplot\n",
    "ax3 = fig.add_subplot(2, 2, 3, projection='3d')\n",
    "ax3.scatter(\n",
    "    df_ssn_sum[\"First Principal Component\"],\n",
    "    df_ssn_sum[\"Second Principal Component\"],\n",
    "    df_ssn_sum[\"Third Principal Component\"],\n",
    "    c=df_ssn_sum[\"Group\"].apply(lambda x: classes.index(x)),\n",
    "    cmap=\"Set1\"\n",
    ")\n",
    "ax3.set_title(\"SeqsleepNet SCL Sum Epoch-Sequence\")\n",
    "ax3.set_xlabel(\"First Principal Component\")\n",
    "ax3.set_ylabel(\"Second Principal Component\")\n",
    "ax3.set_zlabel(\"Third Principal Component\")\n",
    "\n",
    "# Fourth subplot\n",
    "ax4 = fig.add_subplot(2, 2, 4, projection='3d')\n",
    "ax4.scatter(\n",
    "    df_ssn_conc[\"First Principal Component\"],\n",
    "    df_ssn_conc[\"Second Principal Component\"],\n",
    "    df_ssn_conc[\"Third Principal Component\"],\n",
    "    c=df_ssn_conc[\"Group\"].apply(lambda x: classes.index(x)),\n",
    "    cmap=\"Set1\"\n",
    ")\n",
    "ax4.set_title(\"SeqsleepNet SCL Concatenation Epoch-Sequence\")\n",
    "ax4.set_xlabel(\"First Principal Component\")\n",
    "ax4.set_ylabel(\"Second Principal Component\")\n",
    "ax4.set_zlabel(\"Third Principal Component\")\n",
    "\n",
    "plt.savefig(\"scatterplot_3d.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 11))\n",
    "classes=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "# Utilizza seaborn.scatterplot\n",
    "sns.scatterplot(\n",
    "    data=df_ssn,\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"Group\",\n",
    "    hue_order=classes,\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[0, 0],\n",
    ").set(title=\"SeqSleepNet SCL\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_ssn_epoch[(df_ssn_epoch[\"First Principal Component\"] >= -0.4)&(df_ssn_epoch[\"First Principal Component\"] <= 0.4)],\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"Group\",\n",
    "    hue_order=classes,\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[0,1],\n",
    ").set(title=\"SeqSleepNet SCL Epoch encoding\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_ssn_sum,\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"Group\",\n",
    "    hue_order=classes,\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[1, 0],\n",
    ").set(title=\"SeqsleepNet SCL Sum Epoch-Sequence\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_ssn_conc,\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"Group\",\n",
    "    hue_order=classes,\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[1, 1],\n",
    ").set(title=\"SeqsleepNet SCL Concatenation Epoch-Sequence\")\n",
    "\n",
    "plt.savefig(\"scatterplot.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the latent space quality measuring the ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_values = range(2, 10)\n",
    "\n",
    "# Lista per memorizzare i risultati ARI\n",
    "ari_values = []\n",
    "contr_ari_values = []\n",
    "for K in K_values:\n",
    "    # Esegui K-Means con il valore corrente di K\n",
    "    kmeans = KMeans(n_clusters=K, random_state=0).fit(train_projection[true_indx, :])\n",
    "    # Calcola l'ARI confrontando le assegnazioni di K-Means con i true_positive\n",
    "    ari = adjusted_rand_score(true_positive, kmeans.labels_)\n",
    "    # Memorizza il risultato\n",
    "    ari_values.append(ari)\n",
    "\n",
    "    # Esegui K-Means con il valore corrente di K\n",
    "    kmeans = KMeans(n_clusters=K, random_state=0).fit(\n",
    "        contr_train_projections[contr_true_indx, :]\n",
    "    )\n",
    "    # Calcola l'ARI confrontando le assegnazioni di K-Means con i true_positive\n",
    "    ari = adjusted_rand_score(contr_true_positive, kmeans.labels_)\n",
    "    # Memorizza il risultato\n",
    "    contr_ari_values.append(ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"Number of clusters (K)\": K_values,\n",
    "        \"TinySleepNet\": ari_values,\n",
    "        \"ContrTinySleepNet\": contr_ari_values,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Plotta i risultati con Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=results[[\"TinySleepNet\", \"ContrTinySleepNet\"]], marker=\"o\").set(\n",
    "    title=\"Adjusted Rand Index\"\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(train_projection[true_indx, :])\n",
    "contr_kmeans = KMeans(n_clusters=5, random_state=0).fit(\n",
    "    contr_train_projections[contr_true_indx, :]\n",
    ")\n",
    "\n",
    "df[\"KMeans\"] = kmeans.labels_\n",
    "contr_df[\"KMeans\"] = contr_kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 9))\n",
    "\n",
    "# Utilizza seaborn.scatterplot\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"KMeans\",\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[0],\n",
    ").set(title=\"TinySleepNet\")\n",
    "sns.scatterplot(\n",
    "    data=contr_df,\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"KMeans\",\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[1],\n",
    ").set(title=\"ContrTinySleepNet\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources as pkg\n",
    "\n",
    "path = pkg.resource_filename(__name__, \"../\")\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from physioex.explain.ari_explainer import ARIExplainer\n",
    "\n",
    "expl = ARIExplainer(\n",
    "    model_name=\"tinysleepnet\",\n",
    "    dataset_name=\"sleep_physionet\",\n",
    "    ckp_path=\"models/CCL/tinysleepnet/seqlen=3/SleepPhysionet/2018/\",\n",
    "    version=\"2018\",\n",
    "    use_cache=True,\n",
    "    sequence_lenght=3,\n",
    "    batch_size=32,\n",
    "    n_jobs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl.explain(plot_pca=True, plot_kmeans=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
