{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources as pkg\n",
    "\n",
    "path = pkg.resource_filename(__name__, \"../\")\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "#from physioex.data import SleepPhysionet, TimeDistributedModule\n",
    "#from physioex.data import datamodule\n",
    "#from physioex.train.networks import TinySleepNet, ContrTinySleepNet\n",
    "#from physioex.train.networks import seqsleepnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_projections(model, datamodule, contr=False):\n",
    "    train_projections = []\n",
    "    y_train_true = []\n",
    "    y_train_pred = []\n",
    "    first = True\n",
    "    for batch in datamodule.train_dataloader():\n",
    "        inputs, y_true = batch\n",
    "\n",
    "        y_train_true.append(y_true)\n",
    "        if contr:\n",
    "            projections, y_pred = model(inputs.to(model.device))\n",
    "        else:\n",
    "            projections, y_pred = model.encode(inputs.to(model.device))\n",
    "\n",
    "        y_train_pred.append(y_pred.cpu().detach().numpy())\n",
    "        train_projections.append(projections.cpu().detach().numpy())\n",
    "\n",
    "        del projections, y_pred\n",
    "\n",
    "    y_train_true = np.concatenate(y_train_true).reshape(-1)\n",
    "    train_projections = np.concatenate(train_projections).reshape(\n",
    "        y_train_true.shape[0], -1\n",
    "    )\n",
    "    y_train_pred = np.concatenate(y_train_pred).reshape(-1, 5)\n",
    "\n",
    "    return train_projections, y_train_true, y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SleepPhysionet(version=\"2018\", use_cache=True)\n",
    "dataset.split(fold=0)\n",
    "sequence_length = 3\n",
    "batch_size = 32\n",
    "datamodule = TimeDistributedModule(\n",
    "    dataset=dataset,\n",
    "    sequence_lenght=sequence_length,\n",
    "    batch_size=batch_size,\n",
    "    transform=None,\n",
    "    target_transform=None,\n",
    ")\n",
    "\n",
    "ccl_model_path = \"models/CCL/tinysleepnet/seqlen=3/SleepPhysionet/2018/fold=0-epoch=15-step=77670-val_acc=0.79.ckpt\"\n",
    "scl_model_path = \"models/SCL/tinysleepnet/seqlen=3/SleepPhysionet/2018/fold=0-epoch=18-step=93864-val_acc=0.79.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from physioex.models import load_pretrained_model\n",
    "path_ssn = \"/home/tinghi/physioex/models/ssn_scl/fold=-1-epoch=17-step=28348-val_acc=0.83.ckpt\"\n",
    "path_ssn_sum = \"/home/tinghi/physioex/models/ssn_epseq_sum_scl/fold=-1-epoch=18-step=29323-val_acc=0.82.ckpt\"\n",
    "path_ssn_conc = \"/home/tinghi/physioex/models/ssn_epseq_conc_scl/fold=-1-epoch=16-step=25482-val_acc=0.82.ckpt\"\n",
    "path_ssn_epoch = \"/home/tinghi/physioex/models/ssn_ep_scl/fold=-1-epoch=17-step=28348-val_acc=0.81.ckpt\"\n",
    "\n",
    "seqsleepnet_model = load_pretrained_model(\"seqsleepnet\", in_channels=1, sequence_length=10, loss=\"scl\", ckpt_path=path_ssn).eval()\n",
    "seqsleepnet_sum_model = load_pretrained_model(\"seqsleepnet\", in_channels=1, sequence_length=10, loss=\"scl\", ckpt_path=path_ssn_sum).eval()\n",
    "seqsleepnet_conc_model = load_pretrained_model(\"seqsleepnet\", in_channels=1, sequence_length=10, loss=\"scl\", ckpt_path=path_ssn_conc).eval()\n",
    "seqsleepnet_epoch_model = load_pretrained_model(\"seqsleepnet\", in_channels=1, sequence_length=10, loss=\"scl\", ckpt_path=path_ssn_epoch).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-26 08:01:26.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mphysioex.utils.data_folder\u001b[0m:\u001b[36mset_data_folder\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mData folder set to /mnt/guido-data/\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227070\n",
      "2\n",
      "10\n",
      "torch.Size([1, 29, 129])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "from physioex.data.datamodule import PhysioExDataModule\n",
    "\n",
    "datamodule = PhysioExDataModule(\n",
    "    datasets=[\"mass\"],\n",
    "    versions=None,\n",
    "    batch_size=15,\n",
    "    selected_channels=[\"EEG\"],\n",
    "    sequence_length=10,\n",
    "    data_folder=\"/mnt/guido-data/\",\n",
    "    preprocessing = \"xsleepnet\",\n",
    "    target_transform= None,\n",
    ")\n",
    "print(len(datamodule.dataset))\n",
    "print(len(datamodule.dataset[0]))\n",
    "print(len(datamodule.dataset[0][0]))\n",
    "print(datamodule.dataset[0][0][1].shape)\n",
    "print(datamodule.dataset[2359][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Assuming the tensor is obtained from the dataset\n",
    "tensor1 = datamodule.dataset.__getitem__(0)[0][0]\n",
    "tensor2 = datamodule.dataset.__getitem__(1300)[0][0]\n",
    "\n",
    "first_dim = torch.arange(29)\n",
    "second_dim = torch.arange(129)\n",
    "third_dim1 = tensor1[0, first_dim[:, None], second_dim]\n",
    "third_dim2 = tensor2[0, first_dim[:, None], second_dim]\n",
    "# Create a meshgrid for the x and y coordinates\n",
    "X, Y = torch.meshgrid(first_dim, second_dim, indexing='ij')\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Plot the first spectrogram\n",
    "c1 = ax1.pcolormesh(X, Y, third_dim1, shading='auto')\n",
    "fig.colorbar(c1, ax=ax1, label='Intensity')\n",
    "ax1.set_xlabel('First Dimension (x-coordinates)')\n",
    "ax1.set_ylabel('Second Dimension (y-coordinates)')\n",
    "ax1.set_title('Spectrogram 1')\n",
    "\n",
    "# Plot the second spectrogram (assuming you have another tensor for the second plot)\n",
    "# For demonstration, we'll use the same tensor\n",
    "c2 = ax2.pcolormesh(X, Y, third_dim2, shading='auto')\n",
    "fig.colorbar(c2, ax=ax2, label='Intensity')\n",
    "ax2.set_xlabel('First Dimension (x-coordinates)')\n",
    "ax2.set_ylabel('Second Dimension (y-coordinates)')\n",
    "ax2.set_title('Spectrogram 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train dataloader\n",
    "train_dataloader = datamodule.train_dataloader()\n",
    "\n",
    "# Create an iterator from the dataloader\n",
    "train_dataloader_iter = iter(train_dataloader)\n",
    "\n",
    "# Get the first element\n",
    "first_element = next(train_dataloader_iter)\n",
    "\n",
    "# Print the first element\n",
    "print(first_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train dataloader\n",
    "train_dataloader = datamodule.train_dataloader()\n",
    "\n",
    "# Create an iterator from the dataloader\n",
    "train_dataloader_iter = iter(train_dataloader)\n",
    "\n",
    "# Get the first element\n",
    "first_element = next(train_dataloader_iter)\n",
    "\n",
    "# Print the first element\n",
    "print(first_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA components plot\n",
    "\n",
    "### Extracting the latent space projections from the similarity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqsleepnet_model\n",
    "seqsleepnet_sum_model\n",
    "seqsleepnet_conc_model\n",
    "seqsleepnet_epoch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_projections_ssn, y_train_true_ssn, y_train_pred_ssn = compute_projections(\n",
    "    seqsleepnet_model, datamodule, contr=False\n",
    ")\n",
    "preds_snn = np.argmax(y_train_pred_ssn, axis=1)\n",
    "print(train_projections_ssn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssn end\n",
      "ssn sum end\n",
      "ssn conc end\n",
      "ssn epoch end\n"
     ]
    }
   ],
   "source": [
    "train_projections_ssn, y_train_true_ssn, y_train_pred_ssn = compute_projections(\n",
    "    seqsleepnet_model, datamodule, contr=False\n",
    ")\n",
    "preds_snn = np.argmax(y_train_pred_ssn, axis=1)\n",
    "print(\"ssn end\")\n",
    "\n",
    "train_projections_ssn_sum, y_train_true_ssn_sum, y_train_pred_ssn_sum = compute_projections(\n",
    "    seqsleepnet_sum_model, datamodule, contr=False\n",
    ")\n",
    "preds_snn_sum = np.argmax(y_train_pred_ssn_sum, axis=1)\n",
    "print(\"ssn sum end\")\n",
    "\n",
    "train_projections_ssn_conc, y_train_true_ssn_conc, y_train_pred_ssn_conc = compute_projections(\n",
    "    seqsleepnet_conc_model, datamodule, contr=False\n",
    ")\n",
    "preds_snn_conc = np.argmax(y_train_pred_ssn_conc, axis=1)\n",
    "print(\"ssn conc end\")\n",
    "\n",
    "train_projections_ssn_epoch, y_train_true_ssn_epoch, y_train_pred_ssn_epoch = compute_projections(\n",
    "    seqsleepnet_epoch_model, datamodule, contr=False\n",
    ")\n",
    "preds_snn_epoch = np.argmax(y_train_pred_ssn_epoch, axis=1)\n",
    "print(\"ssn epoch end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ContrTinySleepNet.load_from_checkpoint(scl_model_path).eval()\n",
    "contr_train_projections, contr_y_train_true, contr_y_train_pred = compute_projections(\n",
    "    model, datamodule, contr=True\n",
    ")\n",
    "\n",
    "model = TinySleepNet.load_from_checkpoint(ccl_model_path).eval()\n",
    "train_projection, y_train_true, y_train_pred = compute_projections(\n",
    "    model, datamodule, contr=False\n",
    ")\n",
    "\n",
    "# filtering\n",
    "contr_preds = np.argmax(contr_y_train_pred, axis=1)\n",
    "# contr_true_indx = np.where(contr_y_train_true == contr_preds or contr_y_train_true != contr_preds)[0]\n",
    "\n",
    "preds = np.argmax(y_train_pred, axis=1)\n",
    "# true_indx = np.where(y_train_true == preds or y_train_true != preds)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_indx_ssn = [True for i in range(len(y_train_true_ssn))]\n",
    "true_indx_ssn_sum = [True for i in range(len(y_train_true_ssn_sum))]\n",
    "true_indx_ssn_conc = [True for i in range(len(y_train_true_ssn_conc))]\n",
    "true_indx_ssn_epoch = [True for i in range(len(y_train_true_ssn_epoch))]\n",
    "#true_indx = [True for i in range(len(contr_y_train_true))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming train_projections_ssn and y_train_true_ssn are lists or arrays\n",
    "# Convert them to DataFrames if they are not already\n",
    "train_projections_df = pd.DataFrame(train_projections_ssn)\n",
    "y_train_true_df = pd.DataFrame(y_train_true_ssn, columns=['y_train_true_ssn'])\n",
    "\n",
    "# Concatenate along the columns (axis=1)\n",
    "result_df = pd.concat([train_projections_df, y_train_true_df], axis=1)\n",
    "print(result_df.shape)\n",
    "'''\n",
    "print(result_df[result_df['y_train_true_ssn'] == 0].shape)\n",
    "print(result_df[result_df['y_train_true_ssn'] == 1].shape)\n",
    "print(result_df[result_df['y_train_true_ssn'] == 2].shape)\n",
    "print(result_df[result_df['y_train_true_ssn'] == 3].shape)\n",
    "print(result_df[result_df['y_train_true_ssn'] == 4].shape)'''\n",
    "\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "# Sample the dataset\n",
    "sampled_df = result_df.sample(n=10000, random_state=0)  # Adjust the sample size as needed\n",
    "\n",
    "# Apply k-medoids clustering with k=1\n",
    "kmedoids = KMedoids(n_clusters=1, random_state=0)\n",
    "kmedoids.fit(sampled_df.iloc[:, :-1])\n",
    "\n",
    "print(kmedoids.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the first 2 PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio for ssn: [0.3405441  0.17688899]\n",
      "Explained variance: 0.5174331\n",
      "Explained variance ratio for ssn_sum: [0.30972674 0.1700678 ]\n",
      "Explained variance: 0.47979456\n",
      "Explained variance ratio for ssn_conc: [0.27933824 0.1812165 ]\n",
      "Explained variance: 0.46055472\n",
      "Explained variance ratio for ssn_epoch: [0.1714484  0.08993109]\n",
      "Explained variance: 0.26137948\n"
     ]
    }
   ],
   "source": [
    "# Increase the number of components to see the variance in other components\n",
    "pca = PCA(n_components=2)  # Adjust the number of components as needed\n",
    "\n",
    "# First PCA transformation\n",
    "principal_components_ssn = pca.fit_transform(train_projections_ssn[true_indx_ssn, :])\n",
    "true_positive_ssn = y_train_true_ssn[true_indx_ssn]\n",
    "explained_variance_ssn = pca.explained_variance_ratio_\n",
    "\n",
    "df_ssn = pd.DataFrame(\n",
    "    {\n",
    "        \"First Principal Component\": principal_components_ssn[:, 0],\n",
    "        \"Second Principal Component\": principal_components_ssn[:, 1],\n",
    "        #\"Third Principal Component\": principal_components_ssn[:, 2],\n",
    "        \"Group\": true_positive_ssn,\n",
    "    }\n",
    ")\n",
    "print(\"Explained variance ratio for ssn:\", explained_variance_ssn)\n",
    "print(\"Explained variance:\", explained_variance_ssn.sum())\n",
    "\n",
    "# Second PCA transformation\n",
    "principal_components_ssn_sum = pca.fit_transform(train_projections_ssn_sum[true_indx_ssn_sum, :])\n",
    "true_positive_ssn_sum = y_train_true_ssn_sum[true_indx_ssn_sum]\n",
    "explained_variance_ssn_sum = pca.explained_variance_ratio_\n",
    "\n",
    "df_ssn_sum = pd.DataFrame(\n",
    "    {\n",
    "        \"First Principal Component\": principal_components_ssn_sum[:, 0],\n",
    "        \"Second Principal Component\": principal_components_ssn_sum[:, 1],\n",
    "        #\"Third Principal Component\": principal_components_ssn_sum[:, 2],\n",
    "        \"Group\": true_positive_ssn_sum,\n",
    "    }\n",
    ")\n",
    "print(\"Explained variance ratio for ssn_sum:\", explained_variance_ssn_sum)\n",
    "print(\"Explained variance:\", explained_variance_ssn_sum.sum())\n",
    "\n",
    "# Third PCA transformation\n",
    "principal_components_ssn_conc = pca.fit_transform(train_projections_ssn_conc[true_indx_ssn_conc, :])\n",
    "true_positive_ssn_conc = y_train_true_ssn_conc[true_indx_ssn_conc]\n",
    "explained_variance_ssn_conc = pca.explained_variance_ratio_\n",
    "\n",
    "df_ssn_conc = pd.DataFrame(\n",
    "    {\n",
    "        \"First Principal Component\": principal_components_ssn_conc[:, 0],\n",
    "        \"Second Principal Component\": principal_components_ssn_conc[:, 1],\n",
    "        #\"Third Principal Component\": principal_components_ssn_conc[:, 2],\n",
    "        \"Group\": true_positive_ssn_conc,\n",
    "    }\n",
    ")\n",
    "print(\"Explained variance ratio for ssn_conc:\", explained_variance_ssn_conc)\n",
    "print(\"Explained variance:\", explained_variance_ssn_conc.sum())\n",
    "\n",
    "# Fourth PCA transformation\n",
    "principal_components_ssn_epoch = pca.fit_transform(train_projections_ssn_epoch[true_indx_ssn_epoch, :])\n",
    "true_positive_ssn_epoch = y_train_true_ssn_epoch[true_indx_ssn_epoch]\n",
    "explained_variance_ssn_epoch = pca.explained_variance_ratio_\n",
    "\n",
    "df_ssn_epoch = pd.DataFrame(\n",
    "    {\n",
    "        \"First Principal Component\": principal_components_ssn_epoch[:, 0],\n",
    "        \"Second Principal Component\": principal_components_ssn_epoch[:, 1],\n",
    "        #\"Third Principal Component\": principal_components_ssn_epoch[:, 2],\n",
    "        \"Group\": true_positive_ssn_epoch,\n",
    "    }\n",
    ")\n",
    "print(\"Explained variance ratio for ssn_epoch:\", explained_variance_ssn_epoch)\n",
    "print(\"Explained variance:\", explained_variance_ssn_epoch.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0:\"Wake\", 1:\"N1\", 2:\"N2\", 3:\"N3\", 4:\"REM\"}\n",
    "df_ssn[\"Group\"] = df_ssn[\"Group\"].map(classes)\n",
    "df_ssn_epoch[\"Group\"] = df_ssn_epoch[\"Group\"].map(classes)\n",
    "df_ssn_conc[\"Group\"] = df_ssn_conc[\"Group\"].map(classes)\n",
    "df_ssn_sum[\"Group\"] = df_ssn_sum[\"Group\"].map(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base ['N2' 'N1' 'REM' 'N3' 'Wake']\n",
      "Epoch ['Wake' 'N1' 'N2' 'N3' 'REM']\n",
      "Conc ['REM' 'N3' 'N2' 'N1' 'Wake']\n",
      "Sum ['N2' 'REM' 'N1' 'N3' 'Wake']\n"
     ]
    }
   ],
   "source": [
    "print(\"Base\", df_ssn[\"Group\"].unique())\n",
    "print(\"Epoch\", df_ssn_epoch[\"Group\"].unique())\n",
    "print(\"Conc\", df_ssn_conc[\"Group\"].unique())\n",
    "print(\"Sum\", df_ssn_sum[\"Group\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 11))\n",
    "classes=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_ssn_epoch[(df_ssn_epoch[\"First Principal Component\"] >= -0.4)&(df_ssn_epoch[\"First Principal Component\"] <= 0.4)],\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"Group\",\n",
    "    hue_order=classes,\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[0,1],\n",
    ").set(title=\"SeqSleepNet SCL Epoch encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable interactive plotting\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the classes variable\n",
    "classes = [\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "# First subplot\n",
    "ax1 = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "ax1.scatter(\n",
    "    df_ssn[\"First Principal Component\"],\n",
    "    df_ssn[\"Second Principal Component\"],\n",
    "    df_ssn[\"Third Principal Component\"],\n",
    "    c=df_ssn[\"Group\"].apply(lambda x: classes.index(x)),\n",
    "    cmap=\"Set1\"\n",
    ")\n",
    "ax1.set_title(\"SeqSleepNet SCL\")\n",
    "ax1.set_xlabel(\"First Principal Component\")\n",
    "ax1.set_ylabel(\"Second Principal Component\")\n",
    "ax1.set_zlabel(\"Third Principal Component\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the classes variable\n",
    "classes = [\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "\n",
    "fig = plt.figure(figsize=(16, 11))\n",
    "\n",
    "# First subplot\n",
    "ax1 = fig.add_subplot(2, 2, 1, projection='3d')\n",
    "ax1.scatter(\n",
    "    df_ssn[\"First Principal Component\"],\n",
    "    df_ssn[\"Second Principal Component\"],\n",
    "    df_ssn[\"Third Principal Component\"],\n",
    "    c=df_ssn[\"Group\"].apply(lambda x: classes.index(x)),\n",
    "    cmap=\"Set1\"\n",
    ")\n",
    "ax1.set_title(\"SeqSleepNet SCL\")\n",
    "ax1.set_xlabel(\"First Principal Component\")\n",
    "ax1.set_ylabel(\"Second Principal Component\")\n",
    "ax1.set_zlabel(\"Third Principal Component\")\n",
    "\n",
    "# Second subplot\n",
    "ax2 = fig.add_subplot(2, 2, 2, projection='3d')\n",
    "filtered_df = df_ssn_epoch[(df_ssn_epoch[\"First Principal Component\"] >= -0.4) & (df_ssn_epoch[\"First Principal Component\"] <= 0.4)]\n",
    "ax2.scatter(\n",
    "    filtered_df[\"First Principal Component\"],\n",
    "    filtered_df[\"Second Principal Component\"],\n",
    "    filtered_df[\"Third Principal Component\"],\n",
    "    c=filtered_df[\"Group\"].apply(lambda x: classes.index(x)),\n",
    "    cmap=\"Set1\"\n",
    ")\n",
    "ax2.set_title(\"SeqSleepNet SCL Epoch encoding\")\n",
    "ax2.set_xlabel(\"First Principal Component\")\n",
    "ax2.set_ylabel(\"Second Principal Component\")\n",
    "ax2.set_zlabel(\"Third Principal Component\")\n",
    "\n",
    "# Third subplot\n",
    "ax3 = fig.add_subplot(2, 2, 3, projection='3d')\n",
    "ax3.scatter(\n",
    "    df_ssn_sum[\"First Principal Component\"],\n",
    "    df_ssn_sum[\"Second Principal Component\"],\n",
    "    df_ssn_sum[\"Third Principal Component\"],\n",
    "    c=df_ssn_sum[\"Group\"].apply(lambda x: classes.index(x)),\n",
    "    cmap=\"Set1\"\n",
    ")\n",
    "ax3.set_title(\"SeqsleepNet SCL Sum Epoch-Sequence\")\n",
    "ax3.set_xlabel(\"First Principal Component\")\n",
    "ax3.set_ylabel(\"Second Principal Component\")\n",
    "ax3.set_zlabel(\"Third Principal Component\")\n",
    "\n",
    "# Fourth subplot\n",
    "ax4 = fig.add_subplot(2, 2, 4, projection='3d')\n",
    "ax4.scatter(\n",
    "    df_ssn_conc[\"First Principal Component\"],\n",
    "    df_ssn_conc[\"Second Principal Component\"],\n",
    "    df_ssn_conc[\"Third Principal Component\"],\n",
    "    c=df_ssn_conc[\"Group\"].apply(lambda x: classes.index(x)),\n",
    "    cmap=\"Set1\"\n",
    ")\n",
    "ax4.set_title(\"SeqsleepNet SCL Concatenation Epoch-Sequence\")\n",
    "ax4.set_xlabel(\"First Principal Component\")\n",
    "ax4.set_ylabel(\"Second Principal Component\")\n",
    "ax4.set_zlabel(\"Third Principal Component\")\n",
    "\n",
    "plt.savefig(\"scatterplot_3d.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 11))\n",
    "classes=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "# Utilizza seaborn.scatterplot\n",
    "sns.scatterplot(\n",
    "    data=df_ssn,\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"Group\",\n",
    "    hue_order=classes,\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[0, 0],\n",
    ").set(title=\"SeqSleepNet SCL\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_ssn_epoch[(df_ssn_epoch[\"First Principal Component\"] >= -0.4)&(df_ssn_epoch[\"First Principal Component\"] <= 0.4)],\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"Group\",\n",
    "    hue_order=classes,\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[0,1],\n",
    ").set(title=\"SeqSleepNet SCL Epoch encoding\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_ssn_sum,\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"Group\",\n",
    "    hue_order=classes,\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[1, 0],\n",
    ").set(title=\"SeqsleepNet SCL Sum Epoch-Sequence\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_ssn_conc,\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"Group\",\n",
    "    hue_order=classes,\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[1, 1],\n",
    ").set(title=\"SeqsleepNet SCL Concatenation Epoch-Sequence\")\n",
    "\n",
    "plt.savefig(\"scatterplot.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the latent space quality measuring the ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_values = range(2, 10)\n",
    "\n",
    "# Lista per memorizzare i risultati ARI\n",
    "ari_values = []\n",
    "contr_ari_values = []\n",
    "for K in K_values:\n",
    "    # Esegui K-Means con il valore corrente di K\n",
    "    kmeans = KMeans(n_clusters=K, random_state=0).fit(train_projection[true_indx, :])\n",
    "    # Calcola l'ARI confrontando le assegnazioni di K-Means con i true_positive\n",
    "    ari = adjusted_rand_score(true_positive, kmeans.labels_)\n",
    "    # Memorizza il risultato\n",
    "    ari_values.append(ari)\n",
    "\n",
    "    # Esegui K-Means con il valore corrente di K\n",
    "    kmeans = KMeans(n_clusters=K, random_state=0).fit(\n",
    "        contr_train_projections[contr_true_indx, :]\n",
    "    )\n",
    "    # Calcola l'ARI confrontando le assegnazioni di K-Means con i true_positive\n",
    "    ari = adjusted_rand_score(contr_true_positive, kmeans.labels_)\n",
    "    # Memorizza il risultato\n",
    "    contr_ari_values.append(ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"Number of clusters (K)\": K_values,\n",
    "        \"TinySleepNet\": ari_values,\n",
    "        \"ContrTinySleepNet\": contr_ari_values,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Plotta i risultati con Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=results[[\"TinySleepNet\", \"ContrTinySleepNet\"]], marker=\"o\").set(\n",
    "    title=\"Adjusted Rand Index\"\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(train_projection[true_indx, :])\n",
    "contr_kmeans = KMeans(n_clusters=5, random_state=0).fit(\n",
    "    contr_train_projections[contr_true_indx, :]\n",
    ")\n",
    "\n",
    "df[\"KMeans\"] = kmeans.labels_\n",
    "contr_df[\"KMeans\"] = contr_kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 9))\n",
    "\n",
    "# Utilizza seaborn.scatterplot\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"KMeans\",\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[0],\n",
    ").set(title=\"TinySleepNet\")\n",
    "sns.scatterplot(\n",
    "    data=contr_df,\n",
    "    x=\"First Principal Component\",\n",
    "    y=\"Second Principal Component\",\n",
    "    hue=\"KMeans\",\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[1],\n",
    ").set(title=\"ContrTinySleepNet\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources as pkg\n",
    "\n",
    "path = pkg.resource_filename(__name__, \"../\")\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from physioex.explain.ari_explainer import ARIExplainer\n",
    "\n",
    "expl = ARIExplainer(\n",
    "    model_name=\"tinysleepnet\",\n",
    "    dataset_name=\"sleep_physionet\",\n",
    "    ckp_path=\"models/CCL/tinysleepnet/seqlen=3/SleepPhysionet/2018/\",\n",
    "    version=\"2018\",\n",
    "    use_cache=True,\n",
    "    sequence_lenght=3,\n",
    "    batch_size=32,\n",
    "    n_jobs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl.explain(plot_pca=True, plot_kmeans=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physioex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
